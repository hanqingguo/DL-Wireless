{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, taps, whatever, whatever1):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2*taps,whatever)   # 2 意味着每个complex数据，一个实部，一个虚部\n",
    "        self.fc2 = nn.Linear(whatever,whatever1)\n",
    "        self.fc3 = nn.Linear(whatever1,2)       # 2 意味着输出为complex数据\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. -1.]\n",
      " [ 0. -1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "in_data = np.array([1+0j,0-1j,0+1j,-1+0j])\n",
    "in_real = in_data.real\n",
    "in_imag = in_data.imag\n",
    "in_complex = np.stack((in_real, in_imag))\n",
    "print(in_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. -1.]\n",
      " [ 0. -1.  1.  0.]]\n"
     ]
    }
   ],
   "source": [
    "target = np.array([1+0j,0-1j,0+1j,-1+0j])\n",
    "target_real = target.real\n",
    "target_imag = target.imag\n",
    "target_complex = np.stack((target_real, target_imag))\n",
    "print(target_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(taps=2, whatever=10, whatever1=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: [[ 1.  0.  0. -1.]\n",
    "#         [ 0. -1.  1.  0.]]\n",
    "# taps = 2\n",
    "# random_idx = 3\n",
    "# Data_loader return [[0,-1]\n",
    "#                     [1,0]]\n",
    "#\n",
    "# 如果load_input=False, 说明该Data_loader为target取数据 \n",
    "# Data_loader return [[-2],[1]] 取最后一列\n",
    "# 每次取一个随机index， 然后根据filter的taps， 取相关的前几个数据\n",
    "# taps是几，就取几个数据，比如taps是2， 每次取到index， 就再取他前面的那个值， 一共取到两个complex数据\n",
    "\n",
    "def Data_loader(dataset, taps, random_idx, load_input):\n",
    "    if(load_input):\n",
    "        length = dataset.shape[1]\n",
    "        #random_idx = np.random.randint(length)    \n",
    "        if(random_idx==0):\n",
    "            # 如果index是0， 就取本身 和 末尾， 因为是周期性的数\n",
    "            return np.concatenate((dataset[:,length-1:length],\n",
    "                                   dataset[:,random_idx:random_idx+1]), axis=1)\n",
    "\n",
    "        return dataset[:,random_idx-taps+1:random_idx+1]\n",
    "        # return shape = (dataset.shape[0], taps)\n",
    "        # dataset.shape[0] 就是complex number 的real 和 imag\n",
    "    else:\n",
    "        return dataset[:,random_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0. -1.]\n",
      " [ 1.  0.]]\n",
      "[ 0. -1.  1.  0.] [ 0.  1. -1.  0.]\n"
     ]
    }
   ],
   "source": [
    "taps = 2\n",
    "random_idx = np.random.randint(in_complex.shape[1])\n",
    "def flatten_complex(complex_data, taps):\n",
    "    complex_data = complex_data.T.reshape(-1,2*taps)\n",
    "    complex_data = complex_data.squeeze(0)\n",
    "    return complex_data\n",
    "\n",
    "\n",
    "feed_data = Data_loader(in_complex,taps, random_idx, True)\n",
    "print(feed_data)\n",
    "feed_data_0 = feed_data.reshape(-1, 2*taps)\n",
    "feed_data_0 = feed_data_0.squeeze(0)\n",
    "feed_data1 = flatten_complex(feed_data, taps)\n",
    "print(feed_data_0, feed_data1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.Tensor(feed_data1)\n",
    "out = net(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.  1.]\n",
      " [ 0.  0.]]\n",
      "[-1.  0.  1.  0.] [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "random_idx = np.random.randint(in_complex.shape[1])\n",
    "feed_data = Data_loader(in_complex, taps, random_idx, True)\n",
    "target = Data_loader(target_complex, taps, random_idx, False)\n",
    "print(feed_data)\n",
    "feed_data = flatten_complex(feed_data, taps)\n",
    "target = flatten_complex(target, 1)\n",
    "print(feed_data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def train_model(net, optimizer, num_epoch, save_path):\n",
    "    i = 0\n",
    "    best_loss = -1000\n",
    "    best_model_wts = copy.deepcopy(net.state_dict())\n",
    "    while i<num_epoch:\n",
    "        optimizer.zero_grad()\n",
    "        random_idx = np.random.randint(in_complex.shape[1])\n",
    "        feed_data = Data_loader(in_complex, taps, random_idx, True)\n",
    "        target = Data_loader(target_complex, taps, random_idx, False)\n",
    "        feed_data = flatten_complex(feed_data, taps)\n",
    "        target = flatten_complex(target, 1)\n",
    "        feed_data = torch.Tensor(feed_data)\n",
    "        target = torch.Tensor(target)\n",
    "        out = net(feed_data)\n",
    "        #print(out.size(), target.size())\n",
    "        loss = torch.sum((target-out)**2)\n",
    "        if(loss<best_loss):\n",
    "            best_loss = loss\n",
    "            best_model_wts = copy.deepcopy(net.state_dict())\n",
    "            torch.save(model.state_dict(),save_path)\n",
    "        print(\"loss is\\n\\n{}\\n\\n\"\n",
    "              \"input is \\n\\n{}\\n\\n\"\n",
    "              \"predict is \\n\\n{}\\n\\n\"\n",
    "              \"target is \\n\\n{}\\n\\n\".format(loss, feed_data, out, target))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i = i+1\n",
    "    #net.load_state_dict(best_model_wts)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "net = Net(taps=2, whatever=10, whatever1=5)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.009, momentum= 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 1.0000, -0.0000], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 1.0000, -0.0000], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 1.0000, -0.0000], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 1.,  0.,  0., -1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 0., -1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([ 0., -1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 1.,  0.,  0., -1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 0., -1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([ 0., -1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([1.0000e+00, 2.1082e-31], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0.,  1., -1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([-1.0000e+00,  1.1464e-30], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([-1.,  0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([1.0000e+00, 2.8673e-31], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 1.,  0.,  0., -1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([ 0., -1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([ 0., -1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0.,  1., -1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([-1.0000e+00,  1.0387e-30], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([-1.,  0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "1.4210854715202004e-14\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([-1.,  0.,  1.,  0.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([1.0000e+00, 2.4631e-31], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([1., 0.])\n",
      "\n",
      "\n",
      "loss is\n",
      "\n",
      "0.0\n",
      "\n",
      "input is \n",
      "\n",
      "tensor([ 0., -1.,  0.,  1.])\n",
      "\n",
      "predict is \n",
      "\n",
      "tensor([0., 1.], grad_fn=<ThAddBackward>)\n",
      "\n",
      "target is \n",
      "\n",
      "tensor([0., 1.])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(net, optimizer, 20, 'FIR_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.Tensor(np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = trained_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8499, -0.4050], grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
